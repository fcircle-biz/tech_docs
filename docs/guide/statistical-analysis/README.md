# 統計解析 学習ガイドライン

このガイドラインでは、統計解析の基礎から応用までを初心者向けに段階的に学習するためのカリキュラムを提供しています。R言語とPythonの両方を使用し、理論と実践をバランスよく学ぶことで、データ分析の実務に活用できるスキルを身につけます。

## 前提条件

### 必要な環境
- R 4.0以降（RStudioを推奨）
- Python 3.8以降
- 統計解析用ライブラリ
  - R: tidyverse, ggplot2, dplyr
  - Python: pandas, numpy, scipy, statsmodels, matplotlib, seaborn
- 4GB以上のメモリ
- 10GB以上の空きディスク容量

### 参考リソース
- [R公式サイト](https://www.r-project.org/) - 統計解析用プログラミング言語
- [RStudio](https://posit.co/products/open-source/rstudio/) - R開発環境
- [Python公式ドキュメント](https://docs.python.org/ja/3/) - Pythonドキュメント
- [NumPy公式ドキュメント](https://numpy.org/doc/) - 数値計算ライブラリ
- [pandas公式ドキュメント](https://pandas.pydata.org/docs/) - データ分析ライブラリ
- [SciPy公式ドキュメント](https://docs.scipy.org/doc/scipy/) - 科学技術計算ライブラリ

### 前提知識
- **必須**: 基本的なコンピュータ操作スキル、高校数学レベルの知識
- **推奨**: プログラミング経験（Python、Rいずれかの基礎知識）、表計算ソフトの使用経験

## 学習コンテンツ

### [1. 統計解析入門と環境構築](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-1.html)
統計解析とは何か、その重要性と活用場面を理解し、RとPythonの開発環境をセットアップします。基本的なデータの読み込みと表示方法を学習します。

**学習目標:**
- 統計解析の目的と実務での活用場面を理解する
- RとPythonの環境構築とライブラリのインストールができる
- RStudioとJupyter Notebookの基本操作を習得する
- CSVファイルの読み込みとデータ構造の確認ができる

**学習内容:**
1. **統計解析の基礎概念**
   - データサイエンスにおける統計解析の位置づけ
   - 記述統計と推測統計の違い
   - データ分析のプロセス（データ収集、前処理、分析、可視化、解釈）
   - 統計的思考の重要性

2. **R環境のセットアップ**
   - Rのインストールとバージョン確認
   - RStudioのインストールと基本設定
   - パッケージ管理（install.packages, library）
   - 作業ディレクトリの設定とプロジェクト管理

3. **Python環境のセットアップ**
   - Pythonのインストール（Anaconda推奨）
   - Jupyter Notebookの起動と基本操作
   - 統計解析用ライブラリのインストール（pip, conda）
   - 仮想環境の作成と管理

4. **データの読み込みと基本操作**
   - R: read.csv(), read.table(), データフレーム操作
   - Python: pandas.read_csv(), DataFrame基礎
   - データ構造の確認（head, tail, str, info）
   - 変数の選択とフィルタリング

**演習課題:**
- R環境とPython環境の動作確認
- サンプルCSVデータの読み込みと表示
- データの基本情報（行数、列数、列名）の取得
- 簡単なデータ操作（列の抽出、行のフィルタリング）

### [2. 記述統計学の基礎](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-2.html)
データの中心傾向（平均、中央値、最頻値）、ばらつき（分散、標準偏差、範囲）を理解し、ヒストグラムや箱ひげ図を使ったデータの視覚化方法を学習します。

**学習目標:**
- 平均、中央値、最頻値の計算と使い分けができる
- 分散、標準偏差、範囲の意味を理解し計算できる
- ヒストグラム、箱ひげ図、散布図を作成できる
- データの特徴を視覚的に把握し、適切に解釈できる

**学習内容:**
1. **中心傾向の測度**
   - 平均（算術平均、加重平均、幾何平均）
   - 中央値（メディアン）と四分位数
   - 最頻値（モード）
   - 外れ値の影響と適切な測度の選択

2. **ばらつきの測度**
   - 範囲（レンジ）と四分位範囲（IQR）
   - 分散と標準偏差の計算と解釈
   - 変動係数（CV）による相対的ばらつきの評価
   - 外れ値の検出方法

3. **データの分布形状**
   - 歪度（スキューネス）と尖度（クルトシス）
   - 対称分布と非対称分布
   - データ変換（対数変換、平方根変換）
   - 正規性の確認

4. **基本的な視覚化**
   - R: ggplot2によるヒストグラム、箱ひげ図
   - Python: matplotlib, seabornによる可視化
   - 散布図と相関の視覚的確認
   - 複数変数の同時可視化（ペアプロット）

**演習課題:**
- 売上データの平均、中央値、標準偏差の計算
- 複数グループの比較（箱ひげ図を使用）
- 外れ値の検出と処理方法の検討
- データ分布の視覚化と特徴の記述

### [3. 確率の基礎と確率分布](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-3.html)
確率の基本概念、正規分布、二項分布、ポアソン分布などの主要な確率分布を理解し、実データへの当てはめ方法を学習します。

**学習目標:**
- 確率の基本概念と確率変数を理解する
- 正規分布の性質と標準化を理解し活用できる
- 二項分布とポアソン分布の適用場面を理解する
- 確率分布のパラメータ推定ができる

**学習内容:**
1. **確率の基礎**
   - 確率の定義と基本性質
   - 条件付き確率と独立性
   - ベイズの定理の基礎
   - 確率変数と期待値

2. **正規分布（ガウス分布）**
   - 正規分布の性質（平均、分散、対称性）
   - 標準正規分布と標準化（z得点）
   - 68-95-99.7ルール
   - 正規分布表の読み方と活用
   - R: dnorm, pnorm, qnorm, rnorm
   - Python: scipy.stats.norm

3. **二項分布**
   - 二項分布の定義と性質
   - 成功確率とベルヌーイ試行
   - 二項分布の期待値と分散
   - 正規近似の条件
   - R: dbinom, pbinom, qbinom, rbinom
   - Python: scipy.stats.binom

4. **ポアソン分布**
   - ポアソン分布の定義と適用場面
   - 発生率パラメータλの意味
   - 二項分布との関係
   - 実データへの当てはめ
   - R: dpois, ppois, qpois, rpois
   - Python: scipy.stats.poisson

5. **その他の重要な分布**
   - 一様分布、指数分布
   - t分布、カイ二乗分布、F分布（次章の準備）
   - 分布の視覚化と理解

**演習課題:**
- 正規分布を使った確率計算（例：製品の規格外率の推定）
- 二項分布による成功確率の分析（例：コイン投げ実験）
- ポアソン分布による事象発生率の分析（例：時間当たりの来客数）
- 実データへの確率分布の当てはめと適合度評価

### [4. 推測統計の基礎](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-4.html)
標本と母集団の関係、標本分布、中心極限定理を理解し、点推定と区間推定（信頼区間）の方法を学習します。

**学習目標:**
- 標本と母集団の関係を理解する
- 標本分布と中心極限定理の重要性を理解する
- 点推定と区間推定の違いを理解する
- 信頼区間を計算し、適切に解釈できる

**学習内容:**
1. **標本と母集団**
   - 母集団と標本の定義
   - 無作為標本抽出の重要性
   - 標本サイズと推定精度の関係
   - サンプリングバイアスと対策

2. **標本分布と中心極限定理**
   - 標本平均の分布
   - 中心極限定理の理解とシミュレーション
   - 標準誤差（SE）の概念
   - 大数の法則

3. **点推定**
   - 母平均と母比率の点推定
   - 不偏推定量の性質
   - 最尤推定の基礎
   - 推定量の良さの評価（不偏性、一致性、効率性）

4. **区間推定（信頼区間）**
   - 信頼区間の概念と解釈
   - 母平均の信頼区間（母分散既知・未知）
   - 母比率の信頼区間
   - 信頼水準（90%, 95%, 99%）の選択
   - R: t.test(), confint()
   - Python: scipy.stats.t.interval(), statsmodels

5. **標本サイズの決定**
   - 必要標本サイズの計算
   - 誤差の許容範囲と信頼水準のトレードオフ
   - 検出力分析の基礎

**演習課題:**
- 標本平均の分布シミュレーション（中心極限定理の確認）
- 母平均の95%信頼区間の計算（例：製品の平均重量）
- 母比率の信頼区間の計算（例：支持率調査）
- 必要標本サイズの計算（目標精度の設定）

### [5. 仮説検定の基礎](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-5.html)
仮説検定の基本的な考え方、帰無仮説と対立仮説、有意水準とp値を理解し、1標本t検定、2標本t検定、対応のあるt検定を実行します。

**学習目標:**
- 仮説検定の基本的な考え方とプロセスを理解する
- 帰無仮説、対立仮説、有意水準、p値の意味を理解する
- 第1種の誤りと第2種の誤りを理解する
- t検定を適切に選択し実行できる

**学習内容:**
1. **仮説検定の基本概念**
   - 仮説検定のプロセス（仮説設定、検定統計量計算、p値算出、結論）
   - 帰無仮説（H₀）と対立仮説（H₁）
   - 有意水準（α）の設定（通常5%または1%）
   - p値の意味と解釈

2. **検定の誤り**
   - 第1種の誤り（α）：偽陽性
   - 第2種の誤り（β）：偽陰性
   - 検出力（1-β）
   - 両側検定と片側検定

3. **1標本t検定**
   - 母平均が特定の値と異なるかの検定
   - 検定統計量の計算
   - 自由度とt分布
   - R: t.test(x, mu=μ₀)
   - Python: scipy.stats.ttest_1samp()

4. **2標本t検定**
   - 独立した2群の平均の比較
   - 等分散性の検定（F検定、Levene検定）
   - Welchのt検定（等分散を仮定しない）
   - R: t.test(x, y, var.equal=TRUE/FALSE)
   - Python: scipy.stats.ttest_ind()

5. **対応のあるt検定**
   - 対応のあるデータ（前後比較、ペアデータ）
   - 差の平均の検定
   - R: t.test(x, y, paired=TRUE)
   - Python: scipy.stats.ttest_rel()

**演習課題:**
- 製品の平均重量が規格値と異なるかの検定（1標本t検定）
- 新薬と既存薬の効果の比較（2標本t検定）
- トレーニング前後の成績の比較（対応のあるt検定）
- p値の解釈と統計的有意性の判断

### [6. 分散分析とカイ二乗検定](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-6.html)
3群以上の平均値の比較を行う分散分析（ANOVA）、多重比較法、カテゴリカルデータの分析を行うカイ二乗検定を学習します。

**学習目標:**
- 分散分析（ANOVA）の目的と実行方法を理解する
- 多重比較法を使って群間の差を特定できる
- カイ二乗検定を使ってカテゴリカルデータを分析できる
- 効果量の概念と重要性を理解する

**学習内容:**
1. **一元配置分散分析（One-way ANOVA）**
   - ANOVAの基本原理（群間変動と群内変動）
   - F統計量とF分布
   - ANOVAの仮定（正規性、等分散性、独立性）
   - R: aov(), summary()
   - Python: scipy.stats.f_oneway(), statsmodels.formula.api.ols()

2. **多重比較法**
   - 多重比較の問題とファミリーワイズエラー率
   - TukeyのHSD法
   - Bonferroni補正
   - Dunnett法（対照群との比較）
   - R: TukeyHSD()
   - Python: statsmodels.multicomp

3. **二元配置分散分析（Two-way ANOVA）**
   - 2つの要因の効果と交互作用
   - 主効果と交互作用効果の解釈
   - 交互作用プロットの作成
   - R: aov(y ~ factor1 * factor2)
   - Python: statsmodels.formula.api

4. **カイ二乗検定**
   - 適合度検定（Goodness of fit test）
   - 独立性の検定（分割表の分析）
   - クロス集計表の作成と解釈
   - R: chisq.test()
   - Python: scipy.stats.chi2_contingency()

5. **効果量**
   - 統計的有意性と実質的有意性
   - Cohen's d（効果量の指標）
   - η²（イータ二乗）とω²
   - 効果量の解釈基準

**演習課題:**
- 3つの異なる肥料の作物収量への効果の比較（一元配置ANOVA）
- 複数の処理群間の多重比較（TukeyのHSD法）
- 性別と商品嗜好の関連性の分析（カイ二乗独立性検定）
- 観測度数と期待度数の比較（適合度検定）

### [7. 相関と回帰分析](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-7.html)
2変数間の関係性を分析する相関分析、予測モデルを構築する単回帰分析と重回帰分析、モデルの評価方法を学習します。

**学習目標:**
- 相関係数を計算し、変数間の関連性を評価できる
- 単回帰分析でモデルを構築し予測できる
- 重回帰分析で複数の説明変数を扱える
- 回帰モデルの妥当性を評価できる

**学習内容:**
1. **相関分析**
   - ピアソンの積率相関係数
   - スピアマンの順位相関係数
   - 相関係数の検定
   - 擬似相関と交絡因子
   - R: cor(), cor.test()
   - Python: pandas.corr(), scipy.stats.pearsonr()

2. **単回帰分析**
   - 最小二乗法による直線の当てはめ
   - 回帰係数（傾き、切片）の推定と解釈
   - 決定係数（R²）とモデルの説明力
   - 残差分析と仮定の確認
   - R: lm(y ~ x)
   - Python: scipy.stats.linregress(), statsmodels.OLS

3. **重回帰分析**
   - 複数の説明変数によるモデル化
   - 偏回帰係数の意味と解釈
   - 調整済み決定係数
   - 多重共線性の診断（VIF）
   - R: lm(y ~ x1 + x2 + x3)
   - Python: statsmodels.OLS

4. **モデルの診断と評価**
   - 残差プロット（正規性、等分散性、独立性）
   - 外れ値と影響力の大きい点の検出
   - クックの距離、レバレッジ
   - 標準化残差とスチューデント化残差

5. **変数選択**
   - ステップワイズ法（前進選択、後退除去）
   - AIC、BICによるモデル選択
   - 交差検証による汎化性能の評価
   - 過学習の問題

**演習課題:**
- 広告費と売上の相関分析
- 単回帰モデルによる売上予測
- 複数要因を考慮した住宅価格の予測（重回帰分析）
- モデルの診断と改善（残差分析、変数変換）

### [8. 多変量解析入門](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-8.html)
多数の変数を同時に分析する手法として、主成分分析（PCA）、因子分析、クラスター分析を学習し、データの次元削減とパターン発見を行います。

**学習目標:**
- 主成分分析で高次元データを低次元に縮約できる
- 因子分析で潜在因子を抽出できる
- クラスター分析でデータのグループ化ができる
- 多変量データの視覚化と解釈ができる

**学習内容:**
1. **主成分分析（PCA）**
   - 主成分分析の目的と原理
   - 固有値と固有ベクトル
   - 主成分の解釈と寄与率
   - スクリープロット
   - R: prcomp(), princomp()
   - Python: sklearn.decomposition.PCA

2. **因子分析**
   - 因子分析の目的（次元削減と潜在構造の発見）
   - 共通因子と独自因子
   - 因子負荷量と因子回転（バリマックス回転）
   - 因子数の決定方法
   - R: factanal()
   - Python: sklearn.decomposition.FactorAnalysis

3. **階層的クラスター分析**
   - クラスター分析の目的
   - 距離の測度（ユークリッド距離、マンハッタン距離）
   - 結合方法（最短距離法、最長距離法、ウォード法）
   - デンドログラム（樹形図）の作成と解釈
   - R: hclust(), dist()
   - Python: scipy.cluster.hierarchy

4. **非階層的クラスター分析（k-means法）**
   - k-means法のアルゴリズム
   - クラスター数の決定（エルボー法、シルエット係数）
   - クラスターの特徴分析
   - R: kmeans()
   - Python: sklearn.cluster.KMeans

5. **多変量データの視覚化**
   - 散布図行列（ペアプロット）
   - バイプロット（PCAの視覚化）
   - ヒートマップと相関行列の視覚化
   - 次元削減後の2次元・3次元プロット

**演習課題:**
- 消費者アンケートデータの主成分分析
- 心理尺度データからの因子抽出
- 顧客セグメンテーション（クラスター分析）
- クラスターの特徴プロファイリング

### [9. ベイズ統計と時系列分析](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-9.html)
ベイズの定理に基づくベイズ統計の基礎、時系列データの特徴と分析手法、トレンド・季節性・周期性の分析を学習します。

**学習目標:**
- ベイズの定理を理解し、事前分布と事後分布の概念を理解する
- 時系列データの特徴（トレンド、季節性）を理解する
- 自己相関と偏自己相関を計算し解釈できる
- 基本的な時系列モデル（移動平均、ARIMA）を理解する

**学習内容:**
1. **ベイズ統計の基礎**
   - ベイズの定理の復習と拡張
   - 事前分布、尤度、事後分布
   - 共役事前分布
   - ベイズ推定の例（ベルヌーイ分布、正規分布）
   - R: rstanarm, brms, BayesFactor
   - Python: PyMC (pymc), scipy.stats

2. **ベイズ統計の応用**
   - ベイズ的仮説検定
   - ベイズファクター
   - 信頼区間とクレディブル区間
   - MCMCによるサンプリング（概要）

3. **時系列データの基礎**
   - 時系列データの特徴と例
   - トレンド、季節性、周期性、ランダム変動
   - 時系列データの視覚化
   - 移動平均による平滑化

4. **自己相関分析**
   - 自己相関関数（ACF）
   - 偏自己相関関数（PACF）
   - コレログラムの解釈
   - ラグの概念
   - R: acf(), pacf()
   - Python: statsmodels.graphics.tsaplots

5. **時系列モデル**
   - 定常性の概念と検定（ADF検定）
   - 自己回帰モデル（ARモデル）
   - 移動平均モデル（MAモデル）
   - ARIMA モデルの概要
   - 季節性ARIMAモデル（SARIMA）
   - R: auto.arima(), forecast()
   - Python: statsmodels.tsa.arima.model

**演習課題:**
- ベイズ推定による母比率の推定（コイン投げの例）
- 株価データの時系列分析（トレンドと季節性の分解）
- 売上データの自己相関分析
- 簡単な時系列予測モデルの構築

### [10. ノンパラメトリック検定と実践プロジェクト](https://fcircle-biz.github.io/tech_docs/guide/statistical-analysis/statistical-analysis-learning-material-10.html)
正規性の仮定が不要なノンパラメトリック検定（ウィルコクソン検定、マン・ホイットニーのU検定、クラスカル・ウォリス検定）を学び、総合的な統計解析プロジェクトを実施します。

**学習目標:**
- ノンパラメトリック検定の適用場面を理解する
- 順位に基づく検定手法を実行できる
- 複数の統計手法を組み合わせて実データを分析できる
- 分析結果を適切に解釈し報告書を作成できる

**学習内容:**
1. **ノンパラメトリック検定の基礎**
   - ノンパラメトリック検定とは
   - パラメトリック検定との違いと使い分け
   - 順位データの扱い
   - ノンパラメトリック検定の長所と短所

2. **1標本・2標本のノンパラメトリック検定**
   - ウィルコクソンの符号付順位検定（1標本、対応あり）
   - マン・ホイットニーのU検定（2標本、独立）
   - コルモゴロフ・スミルノフ検定（分布の比較）
   - R: wilcox.test(), ks.test()
   - Python: scipy.stats.wilcoxon(), mannwhitneyu()

3. **多群のノンパラメトリック検定**
   - クラスカル・ウォリス検定（3群以上の比較）
   - フリードマン検定（対応あり複数群）
   - 多重比較（Steel-Dwass法、Dunn法）
   - R: kruskal.test(), friedman.test()
   - Python: scipy.stats.kruskal()

4. **カテゴリカルデータのノンパラメトリック検定**
   - フィッシャーの正確確率検定
   - マクネマー検定（対応のある2値データ）
   - コクランのQ検定
   - R: fisher.test(), mcnemar.test()
   - Python: scipy.stats.fisher_exact()

5. **実践プロジェクト：総合データ分析**
   - **プロジェクト例1: マーケティングデータ分析**
     - 顧客データの記述統計
     - セグメンテーション（クラスター分析）
     - キャンペーン効果の検証（A/Bテスト）
     - 購買予測モデルの構築（ロジスティック回帰）

   - **プロジェクト例2: 医療・健康データ分析**
     - 臨床試験データの分析
     - 治療効果の検定（t検定、ANOVA）
     - リスク因子の分析（回帰分析）
     - 生存時間分析の基礎

   - **プロジェクト例3: 製造業の品質管理**
     - 工程能力分析
     - 不良率の推移分析（時系列分析）
     - 要因分析（相関・回帰分析）
     - 管理図の作成

6. **分析結果の報告とプレゼンテーション**
   - 統計レポートの構成
   - 図表の効果的な作成
   - 統計的有意性の解釈と注意点
   - 再現可能な分析（R Markdown, Jupyter Notebook）

**最終課題:**
実データを使った総合的な統計解析プロジェクトを実施し、以下の要件を満たすレポートを作成する：
- 明確な分析目的と仮説の設定
- 適切な手法の選択と実行（最低3種類の統計手法を使用）
- 視覚化を含む分析結果の提示
- 統計的解釈と実務的な示唆
- 再現可能なコード（R MarkdownまたはJupyter Notebook形式）

## 学習の進め方

1. **環境構築から開始**: 第1章でRとPythonの環境を整え、基本的なデータ操作に慣れましょう。両方の言語に触れることで、それぞれの特徴を理解できます。

2. **理論と実践のバランス**: 各章で理論的な背景を学んだ後、必ず実際のデータで演習を行いましょう。手を動かすことが理解への近道です。

3. **視覚化の活用**: データの特徴や分析結果は必ず可視化し、視覚的に理解する習慣をつけましょう。グラフは数値以上に多くの情報を伝えます。

4. **仮定の確認**: 各統計手法には前提条件があります。検定を実行する前に、データが仮定を満たしているか必ず確認しましょう。

5. **段階的な学習**: 基礎から応用へ段階的に進みます。焦らず、各章の内容を確実に理解してから次に進みましょう。

6. **実データでの実践**: 公開データセットやKaggleのデータを使って、学んだ手法を実際に適用してみましょう。

7. **コミュニティ活用**: R、Pythonともに活発なコミュニティがあります。分からないことがあれば、Stack OverflowやQiitaなどで質問しましょう。

## 推奨学習期間

- **基礎統計コース** (1-4章): 4-5週間
- **検定・分析手法コース** (5-7章): 5-6週間
- **高度な分析手法コース** (8-10章): 5-6週間
- **合計学習期間**: 14-17週間（週5-8時間の学習を想定）

## 関連リソース

- [Python データ分析チートシート](https://fcircle-biz.github.io/tech_docs/cheatsheet/python/python-data-analysis-cheatsheet.html) - pandasとnumpyの基本操作
- [R言語 学習ガイドライン](../r-ecosystem/r/README.md) - R言語の詳細な学習ガイド
- [Python 学習ガイドライン](../python-ecosystem/python/README.md) - Pythonの基礎学習
- 機械学習入門ガイドライン（準備中） - 統計学習の次のステップ

## 学習目標

このガイドを完了すると、以下のスキルを身につけることができます：

- 記述統計量を計算し、データの特徴を適切に要約できる
- データの視覚化を効果的に行い、パターンや異常値を発見できる
- 主要な確率分布を理解し、実データに適用できる
- 信頼区間を計算し、推定の精度を評価できる
- 適切な仮説検定を選択し、実行・解釈できる
- 分散分析とカイ二乗検定を使って複数群を比較できる
- 相関分析と回帰分析で変数間の関係を分析できる
- 多変量解析手法を使ってデータの構造を理解できる
- ベイズ統計の基本概念を理解し、簡単な分析ができる
- 時系列データの特徴を分析し、基本的な予測ができる
- ノンパラメトリック検定を適切に選択・実行できる
- RとPythonの両方で統計解析を実装できる
- 分析結果を適切に解釈し、レポートとして報告できる

## 次のステップ

このガイドライン完了後は、以下の学習に進むことをお勧めします：

- 機械学習入門（準備中） - 予測モデルの構築と評価
- R言語による高度なデータ分析（準備中） - Rの高度な機能
- Pythonデータサイエンス実践（準備中） - 大規模データ分析
- 実験計画法（準備中） - 科学的実験の設計と分析
- 生存時間分析（準備中） - 医療統計の専門分野
