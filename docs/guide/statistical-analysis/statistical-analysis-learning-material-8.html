<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>統計解析学習教材 第8章 - 多変量解析入門</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <style>
        body { font-family: 'Noto Sans JP', sans-serif; padding-top: 56px; background-color: #f8f9fa; }
        .navbar { background-color: #1e88e5; }
        .sidebar { position: sticky; top: 70px; height: calc(100vh - 70px); overflow-y: auto; background-color: #ffffff; border-right: 1px solid #dee2e6; padding: 1rem; }
        .sidebar .nav-link { color: #495057; padding: 0.5rem 1rem; border-radius: 5px; margin-bottom: 0.25rem; }
        .sidebar .nav-link:hover { background-color: #e3f2fd; }
        .sidebar .nav-link.active { background-color: #1e88e5 !important; color: white !important; }
        .chapter-title { color: #1e88e5; margin-top: 1.5rem; margin-bottom: 1rem; border-bottom: 3px solid #1e88e5; padding-bottom: 0.5rem; }
        .section-title { color: #42a5f5; margin-top: 2rem; margin-bottom: 1rem; border-left: 4px solid #42a5f5; padding-left: 0.75rem; }
        .highlight { background-color: #fff3e0; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; border-left: 4px solid #ff9800; }
        .quiz-container { background-color: #e3f2fd; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; border-left: 4px solid #1e88e5; }
        .exercise-container { background-color: #f3e5f5; border-radius: 8px; padding: 1.5rem; margin: 1.5rem 0; border-left: 4px solid #9c27b0; }
        .code-block { background-color: #1e1e1e; color: white; border-radius: 5px; padding: 1rem; margin: 1rem 0; overflow-x: auto; }
        main { background-color: #ffffff; min-height: calc(100vh - 56px); padding: 2rem; }
        footer { margin-top: 3rem; background-color: #1e88e5; }
    </style>
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top">
        <div class="container-fluid"><a class="navbar-brand" href="#"><strong>統計解析学習教材</strong></a></div>
    </nav>
    <div class="container-fluid">
        <div class="row">
            <nav id="sidebarMenu" class="col-md-3 col-lg-2 d-md-block sidebar collapse">
                <div class="position-sticky pt-3">
                    <h6 class="sidebar-heading d-flex justify-content-between align-items-center px-3 mt-4 mb-1 text-muted"><span>学習章</span></h6>
                    <ul class="nav flex-column">
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-1.html">第1章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-2.html">第2章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-3.html">第3章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-4.html">第4章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-5.html">第5章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-6.html">第6章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-7.html">第7章</a></li>
                        <li class="nav-item"><a class="nav-link active" href="statistical-analysis-learning-material-8.html">第8章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-9.html">第9章</a></li>
                        <li class="nav-item"><a class="nav-link" href="statistical-analysis-learning-material-10.html">第10章</a></li>
                    </ul>
                </div>
            </nav>
            <main class="col-md-9 ms-sm-auto col-lg-10 px-md-4">
                <div class="d-flex justify-content-between flex-wrap flex-md-nowrap align-items-center pt-3 pb-2 mb-3 border-bottom">
                    <h1 class="h2">第8章: 多変量解析入門</h1>
                </div>
                <div id="chapter8">
                    <div class="highlight">
                        <h5>この章で学ぶこと</h5>
                        <ul>
                            <li>主成分分析で高次元データを低次元に縮約できる</li>
                            <li>因子分析で潜在因子を抽出できる</li>
                            <li>クラスター分析でデータのグループ化ができる</li>
                            <li>多変量データの視覚化と解釈ができる</li>
                        </ul>
                    </div>

                    <h3 class="section-title">8.1 主成分分析（PCA）</h3>
                    <h4>主成分分析とは</h4>
                    <p>
                        主成分分析（Principal Component Analysis, PCA）は、多数の変数を少数の合成変数（主成分）に縮約する手法です。
                        データの情報を最大限保持しながら次元を削減し、可視化や解釈を容易にします。
                    </p>

                    <div class="mermaid">
                        flowchart LR
                            A["高次元データ<br/>(p個の変数)"] --> B["主成分分析<br/>(PCA)"]
                            B --> C["低次元データ<br/>(2-3個の主成分)"]
                            C --> D[可視化・解釈]

                            style A fill:#e3f2fd
                            style B fill:#fff3e0
                            style C fill:#e8f5e9
                            style D fill:#f3e5f5
                    </div>

                    <pre class="code-block"><code class="language-r"># R: 主成分分析
# アイリスデータセットを使用
data(iris)
iris_data <- iris[, 1:4]  # 数値変数のみ

# PCA実行
pca_result <- prcomp(iris_data, scale=TRUE)

# 結果の確認
summary(pca_result)

# 主成分得点
head(pca_result$x)

# バイプロット（第1・第2主成分）
biplot(pca_result, scale=0)

# 寄与率の可視化
screeplot(pca_result, type="lines", main="スクリープロット")</code></pre>

                    <pre class="code-block"><code class="language-python"># Python: 主成分分析
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import pandas as pd
import matplotlib.pyplot as plt

# データ準備（Irisデータ）
from sklearn.datasets import load_iris
iris = load_iris()
X = iris.data

# データの標準化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA実行（2次元に縮約）
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# 寄与率の確認
print(f"寄与率: {pca.explained_variance_ratio_}")
print(f"累積寄与率: {pca.explained_variance_ratio_.cumsum()}")

# 可視化
plt.scatter(X_pca[:, 0], X_pca[:, 1])
plt.xlabel('第1主成分')
plt.ylabel('第2主成分')
plt.title('主成分分析の結果')
plt.show()</code></pre>

                    <h4>主成分の解釈</h4>
                    <p>
                        各主成分は元の変数の線形結合です。
                        主成分負荷量を見ることで、どの変数が各主成分に寄与しているかがわかります。
                    </p>

                    <h3 class="section-title">8.2 因子分析</h3>
                    <h4>因子分析とは</h4>
                    <p>
                        因子分析は、観測された変数の背後にある潜在的な因子（共通因子）を抽出する手法です。
                        心理学や社会科学の分野で、質問項目から潜在的な概念を抽出する際によく使われます。
                    </p>

                    <pre class="code-block"><code class="language-r"># R: 因子分析
# データ準備
data(mtcars)

# 因子数2で因子分析
fa_result <- factanal(mtcars[, 1:7], factors=2)
print(fa_result)

# 因子負荷量の確認
print(fa_result$loadings)

# バリマックス回転（因子の解釈を容易にする）
fa_rotated <- factanal(mtcars[, 1:7], factors=2, rotation="varimax")
print(fa_rotated$loadings)</code></pre>

                    <pre class="code-block"><code class="language-python"># Python: 因子分析
from sklearn.decomposition import FactorAnalysis
import numpy as np

# データ準備
X = np.random.randn(100, 5)

# 因子分析（2因子）
fa = FactorAnalysis(n_components=2)
X_fa = fa.fit_transform(X)

# 因子負荷量
print("因子負荷量:")
print(fa.components_)</code></pre>

                    <h3 class="section-title">8.3 階層的クラスター分析</h3>
                    <h4>クラスター分析とは</h4>
                    <p>
                        クラスター分析は、類似した観測をグループ（クラスター）に分ける手法です。
                        階層的クラスター分析では、デンドログラム（樹形図）を作成し、グループ化の過程を可視化します。
                    </p>

                    <pre class="code-block"><code class="language-r"># R: 階層的クラスター分析
data(iris)
iris_data <- iris[, 1:4]

# 距離行列の計算（ユークリッド距離）
dist_matrix <- dist(iris_data)

# 階層的クラスター分析（ウォード法）
hc_result <- hclust(dist_matrix, method="ward.D2")

# デンドログラムの作成
plot(hc_result, main="デンドログラム",
     xlab="", sub="", cex=0.7)

# クラスター数を3に決定
clusters <- cutree(hc_result, k=3)
table(clusters)</code></pre>

                    <pre class="code-block"><code class="language-python"># Python: 階層的クラスター分析
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris

# データ準備
iris = load_iris()
X = iris.data

# 階層的クラスタリング（ウォード法）
linkage_matrix = linkage(X, method='ward')

# デンドログラムの作成
plt.figure(figsize=(10, 5))
dendrogram(linkage_matrix)
plt.title('デンドログラム')
plt.xlabel('サンプル')
plt.ylabel('距離')
plt.show()</code></pre>

                    <h3 class="section-title">8.4 k-means法（非階層的クラスター分析）</h3>
                    <h4>k-means法とは</h4>
                    <p>
                        k-means法は、データをk個のクラスターに分割する代表的な非階層的クラスタリング手法です。
                        クラスター数kを事前に指定する必要があります。
                    </p>

                    <pre class="code-block"><code class="language-r"># R: k-means法
data(iris)
iris_data <- iris[, 1:4]

# k-meansクラスタリング（k=3）
kmeans_result <- kmeans(iris_data, centers=3)

# クラスター中心
print(kmeans_result$centers)

# クラスター割り当て
table(kmeans_result$cluster, iris$Species)

# 可視化（第1・第2主成分で）
pca <- prcomp(iris_data, scale=TRUE)
plot(pca$x[,1:2], col=kmeans_result$cluster, pch=19,
     main="k-meansクラスタリング結果")</code></pre>

                    <pre class="code-block"><code class="language-python"># Python: k-means法
from sklearn.cluster import KMeans
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# データ準備
iris = load_iris()
X = iris.data

# k-meansクラスタリング（k=3）
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)

# クラスター中心
print("クラスター中心:")
print(kmeans.cluster_centers_)

# エルボー法（最適なクラスター数の決定）
inertias = []
for k in range(1, 10):
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X)
    inertias.append(km.inertia_)

plt.plot(range(1, 10), inertias, marker='o')
plt.xlabel('クラスター数')
plt.ylabel('慣性')
plt.title('エルボー法')
plt.show()</code></pre>

                    <div class="exercise-container">
                        <h5>実習 8-1: 多変量解析の実践</h5>
                        <p><strong>課題1: 主成分分析</strong></p>
                        <p>
                            組み込みデータセット（mtcarsやiris）を使って主成分分析を実行し、以下を確認してください：
                        </p>
                        <ol>
                            <li>第1主成分と第2主成分の累積寄与率</li>
                            <li>各主成分の解釈（どの変数が寄与しているか）</li>
                            <li>バイプロットまたは散布図による可視化</li>
                        </ol>

                        <p><strong>課題2: クラスター分析</strong></p>
                        <p>
                            顧客データ（年齢、購入金額、購入頻度など）を想定し、クラスター分析を実行してください：
                        </p>
                        <ol>
                            <li>階層的クラスター分析でデンドログラムを作成</li>
                            <li>k-means法で3つのセグメントに分類</li>
                            <li>各クラスターの特徴を記述</li>
                        </ol>
                    </div>

                    <div class="quiz-container">
                        <h5>理解度確認クイズ</h5>
                        <ol>
                            <li>主成分分析の主な目的を説明してください。</li>
                            <li>因子分析と主成分分析の違いは何ですか？</li>
                            <li>階層的クラスター分析と非階層的クラスター分析の違いを説明してください。</li>
                            <li>k-means法でクラスター数を決定する方法を2つ挙げてください。</li>
                            <li>PCAで累積寄与率が80%の意味を説明してください。</li>
                        </ol>
                    </div>

                    <div class="d-flex justify-content-between mt-4 mb-4">
                        <a href="statistical-analysis-learning-material-7.html" class="btn btn-secondary">← 前の章</a>
                        <a href="statistical-analysis-learning-material-9.html" class="btn btn-primary">次の章 →</a>
                    </div>
                </div>
            </main>
        </div>
    </div>
    <footer class="text-white mt-5">
        <div class="container-fluid py-3">
            <div class="row">
                <div class="col-12 text-center">
                    <p class="mb-0">© 2025 F-Circle. All rights reserved.</p>
                </div>
            </div>
        </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script>mermaid.initialize({ startOnLoad: true, theme: 'default' });</script>
</body>
</html>