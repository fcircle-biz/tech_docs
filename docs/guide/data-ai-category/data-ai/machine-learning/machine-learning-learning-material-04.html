<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>機械学習学習教材 第4章 - 教師あり学習：回帰</title>

    <!-- Bootstrap 5 CDN -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Google Fonts - Noto Sans JP -->
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&display=swap" rel="stylesheet">

    <!-- Highlight.js CDN -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

    <!-- Mermaid.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>

    <style>
        body {
            font-family: 'Noto Sans JP', sans-serif;
            padding-top: 56px;
        }

        .navbar {
            background-color: #00897B;
        }

        .sidebar {
            position: sticky;
            top: 70px;
            height: calc(100vh - 70px);
            overflow-y: auto;
            background-color: #f8f9fa;
            padding: 1rem;
        }

        .chapter-title {
            color: #00897B;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            border-bottom: 3px solid #00897B;
            padding-bottom: 0.5rem;
        }

        .section-title {
            color: #26a69a;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            padding-left: 0.5rem;
            border-left: 4px solid #26a69a;
        }

        .quiz-container {
            background-color: #e0f2f1;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-left: 4px solid #00897B;
        }

        .exercise-container {
            background-color: #f3e5f5;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-left: 4px solid #9c27b0;
        }

        .highlight {
            background-color: #fff9c4;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            border-left: 4px solid #fbc02d;
        }

        .warning {
            background-color: #ffebee;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            border-left: 4px solid #f44336;
        }

        .code-block {
            background-color: #1e1e1e;
            color: white;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
        }

        .nav-link.active {
            background-color: #00897B !important;
            color: white !important;
            border-radius: 5px;
        }

        .nav-link {
            color: #333;
            transition: all 0.3s;
        }

        .nav-link:hover {
            background-color: #e0f2f1;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <!-- ナビゲーションバー -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="README.html">
                <strong>機械学習学習教材</strong>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
        </div>
    </nav>

    <div class="container-fluid">
        <div class="row">
            <!-- サイドバー -->
            <nav id="sidebarMenu" class="col-md-3 col-lg-2 d-md-block sidebar collapse">
                <div class="position-sticky pt-3">
                    <h6 class="sidebar-heading d-flex justify-content-between align-items-center px-3 mt-4 mb-1 text-muted">
                        <span>学習章</span>
                    </h6>
                    <ul class="nav flex-column">
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-01.html">
                                第1章: 機械学習の概要と環境構築
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-02.html">
                                第2章: 機械学習の基礎概念
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-03.html">
                                第3章: データの前処理
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link active" href="machine-learning-learning-material-04.html">
                                第4章: 教師あり学習：回帰
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-05.html">
                                第5章: 教師あり学習：分類
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-06.html">
                                第6章: モデルの評価と検証
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-07.html">
                                第7章: 特徴量エンジニアリング
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-08.html">
                                第8章: アンサンブル学習
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-09.html">
                                第9章: 教師なし学習
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-10.html">
                                第10章: 実践プロジェクト開発
                            </a>
                        </li>
                    </ul>
                </div>
            </nav>

            <!-- メインコンテンツ -->
            <main class="col-md-9 ms-sm-auto col-lg-10 px-md-4">
                <div class="d-flex justify-content-between flex-wrap flex-md-nowrap align-items-center pt-3 pb-2 mb-3 border-bottom">
                    <h1 class="h2">第4章: 教師あり学習：回帰</h1>
                </div>

                <div id="chapter4">
                    <h2 class="chapter-title">回帰分析の理論と実装</h2>

                    <div class="highlight">
                        <h5>この章で学ぶこと</h5>
                        <ul>
                            <li>回帰問題の定義と応用分野を理解する</li>
                            <li>線形回帰の数学的な仕組みを学ぶ</li>
                            <li>多項式回帰で非線形パターンを捉える</li>
                            <li>正則化技術（Ridge、Lasso、ElasticNet）で過学習を防ぐ</li>
                            <li>回帰モデルの性能を適切に評価する</li>
                        </ul>
                    </div>

                    <h3 class="section-title">4.1 回帰とは何か</h3>
                    <p>
                        <strong>回帰（Regression）</strong>は、教師あり学習の一種で、入力変数（特徴量）から連続値を予測する問題です。
                        分類問題がカテゴリを予測するのに対し、回帰問題は具体的な数値を予測します。
                    </p>

                    <h4>回帰問題の実例</h4>
                    <ul>
                        <li><strong>不動産価格予測</strong>: 物件の面積、築年数、駅からの距離などから販売価格を予測</li>
                        <li><strong>売上予測</strong>: 広告費、季節、過去のトレンドから将来の売上を予測</li>
                        <li><strong>需要予測</strong>: 気温、曜日、イベント情報から商品の需要量を予測</li>
                        <li><strong>株価予測</strong>: 過去の株価、取引量、経済指標から将来の株価を予測</li>
                        <li><strong>気温予測</strong>: 過去の気象データから翌日の気温を予測</li>
                    </ul>

                    <div class="mermaid">
                        flowchart LR
                            A["入力データ<br/>（特徴量）"] --> B["回帰モデル"]
                            B --> C["連続値の予測<br/>（例: 価格、気温）"]
                            style A fill:#e3f2fd
                            style B fill:#c8e6c9
                            style C fill:#fff9c4
                    </div>

                    <h3 class="section-title">4.2 線形回帰の理論</h3>
                    <p>
                        <strong>線形回帰（Linear Regression）</strong>は、最も基本的な回帰アルゴリズムです。
                        入力変数と出力変数の間に直線的な関係を仮定し、その関係を表す最適な直線を見つけます。
                    </p>

                    <h4>単回帰と重回帰</h4>
                    <ul>
                        <li>
                            <strong>単回帰（Simple Linear Regression）</strong>:
                            1つの特徴量から予測を行う。式は <code>y = ax + b</code> の形式。
                            例：面積だけから住宅価格を予測
                        </li>
                        <li>
                            <strong>重回帰（Multiple Linear Regression）</strong>:
                            複数の特徴量から予測を行う。式は <code>y = a₁x₁ + a₂x₂ + ... + aₙxₙ + b</code> の形式。
                            例：面積、築年数、駅距離から住宅価格を予測
                        </li>
                    </ul>

                    <div class="mermaid">
                        flowchart TD
                            A[線形回帰] --> B[単回帰]
                            A --> C[重回帰]
                            B --> D["y = ax + b<br/>（1つの特徴量）"]
                            C --> E["y = a₁x₁ + a₂x₂ + ... + b<br/>（複数の特徴量）"]
                            style A fill:#00897B,color:#fff
                            style B fill:#4db6ac
                            style C fill:#4db6ac
                    </div>

                    <h4>最小二乗法とは</h4>
                    <p>
                        線形回帰は<strong>最小二乗法（Least Squares Method）</strong>を使って、
                        予測値と実際の値の差（残差）の二乗和を最小化する直線を求めます。
                    </p>
                    <p>
                        <strong>残差</strong> = 実際の値 - 予測値<br>
                        目標：すべてのデータ点について、残差の二乗和を最小にする
                    </p>

                    <div class="exercise-container">
                        <h5>実習 4-1: 単回帰モデルの実装</h5>
                        <p>面積から住宅価格を予測する単回帰モデルを構築します。</p>
                        <h6>手順</h6>
                        <ol>
                            <li>サンプルデータを作成する</li>
                            <li>LinearRegressionモデルを訓練する</li>
                            <li>予測を行い、結果を可視化する</li>
                        </ol>
                        <h6>実装例</h6>
                        <pre class="code-block"><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# サンプルデータ: 面積（㎡）と価格（万円）
area = np.array([50, 60, 70, 80, 90, 100]).reshape(-1, 1)
price = np.array([2500, 3000, 3200, 3800, 4200, 4500])

# モデルの作成と訓練
model = LinearRegression()
model.fit(area, price)  # データからパターンを学習

# 予測
predicted = model.predict(area)

print(f"傾き: {model.coef_[0]:.2f}")  # 面積1㎡あたりの価格上昇
print(f"切片: {model.intercept_:.2f}")  # 基本価格</code></pre>
                        <h6>期待される結果</h6>
                        <p>
                            傾きは面積が1㎡増えるごとの価格上昇を示し、切片は面積0のときの基本価格を表します。
                            モデルは訓練データに最もフィットする直線を見つけます。
                        </p>
                    </div>

                    <h3 class="section-title">4.3 多項式回帰</h3>
                    <p>
                        実世界のデータは必ずしも直線的な関係ではありません。
                        <strong>多項式回帰（Polynomial Regression）</strong>は、
                        曲線的なパターンを捉えるために、特徴量の2乗、3乗などを追加する手法です。
                    </p>

                    <h4>多項式回帰の考え方</h4>
                    <ul>
                        <li><strong>1次（線形）</strong>: y = ax + b → 直線</li>
                        <li><strong>2次</strong>: y = ax² + bx + c → 放物線</li>
                        <li><strong>3次</strong>: y = ax³ + bx² + cx + d → S字カーブ</li>
                        <li><strong>n次</strong>: より複雑な曲線パターン</li>
                    </ul>

                    <div class="warning">
                        <h5>注意：多項式の次数選択</h5>
                        <p>
                            次数を高くしすぎると、訓練データに過度にフィットし、
                            新しいデータへの予測精度が下がる<strong>過学習</strong>が発生します。
                            適切な次数はバリデーションデータで評価して決定します。
                        </p>
                    </div>

                    <div class="mermaid">
                        flowchart TD
                            A["元の特徴量<br/>x"] --> B["多項式特徴量変換"]
                            B --> C["x, x², x³, ..."]
                            C --> D[線形回帰モデル]
                            D --> E["曲線的な予測"]
                            style A fill:#e3f2fd
                            style B fill:#c8e6c9
                            style D fill:#c8e6c9
                            style E fill:#fff9c4
                    </div>

                    <div class="exercise-container">
                        <h5>実習 4-2: 多項式回帰の実装</h5>
                        <p>非線形パターンを持つデータに対して多項式回帰を適用します。</p>
                        <h6>実装例</h6>
                        <pre class="code-block"><code class="language-python">from sklearn.preprocessing import PolynomialFeatures

# 2次の多項式特徴量を生成
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(area)  # [1, x, x²]に変換

# 多項式回帰モデルの訓練
poly_model = LinearRegression()
poly_model.fit(X_poly, price)

# 予測
predicted_poly = poly_model.predict(X_poly)</code></pre>
                        <h6>解説</h6>
                        <p>
                            PolynomialFeaturesは元の特徴量から多項式の特徴量を自動生成します。
                            degree=2の場合、x から [1, x, x²] を生成し、より複雑なパターンを捉えます。
                        </p>
                    </div>

                    <h3 class="section-title">4.4 正則化：過学習を防ぐ</h3>
                    <p>
                        <strong>正則化（Regularization）</strong>は、モデルが訓練データに過度にフィットするのを防ぎ、
                        新しいデータへの汎化性能を高める技術です。
                        重みパラメータの大きさにペナルティを課すことで、モデルの複雑さを制御します。
                    </p>

                    <h4>主要な正則化手法</h4>

                    <h5>1. Ridge回帰（L2正則化）</h5>
                    <ul>
                        <li>重みの二乗和にペナルティを課す</li>
                        <li>すべての重みを小さくするが、0にはしない</li>
                        <li>多重共線性（特徴量間の相関）に強い</li>
                        <li>パラメータα（アルファ）で正則化の強さを調整</li>
                    </ul>

                    <h5>2. Lasso回帰（L1正則化）</h5>
                    <ul>
                        <li>重みの絶対値の和にペナルティを課す</li>
                        <li>重要でない特徴量の重みを完全に0にする</li>
                        <li>特徴量選択の効果がある</li>
                        <li>解釈しやすいシンプルなモデルを作成</li>
                    </ul>

                    <h5>3. ElasticNet（L1 + L2の組み合わせ）</h5>
                    <ul>
                        <li>RidgeとLassoの利点を組み合わせる</li>
                        <li>多重共線性に対処しつつ、特徴量選択も行う</li>
                        <li>2つのパラメータ（α、l1_ratio）で調整</li>
                    </ul>

                    <div class="mermaid">
                        flowchart TD
                            A[正則化回帰] --> B["Ridge<br/>（L2正則化）"]
                            A --> C["Lasso<br/>（L1正則化）"]
                            A --> D["ElasticNet<br/>（L1 + L2）"]
                            B --> E["重みを小さく<br/>0にはしない"]
                            C --> F["不要な重みを0に<br/>特徴量選択"]
                            D --> G["両方の利点を<br/>組み合わせ"]
                            style A fill:#00897B,color:#fff
                    </div>

                    <div class="exercise-container">
                        <h5>実習 4-3: 正則化回帰の実装</h5>
                        <p>Ridge、Lasso、ElasticNetの3つの正則化手法を比較します。</p>
                        <h6>実装例</h6>
                        <pre class="code-block"><code class="language-python">from sklearn.linear_model import Ridge, Lasso, ElasticNet

# Ridge回帰（L2正則化）
ridge = Ridge(alpha=1.0)  # αが大きいほど正則化が強い
ridge.fit(X_train, y_train)

# Lasso回帰（L1正則化）
lasso = Lasso(alpha=1.0)
lasso.fit(X_train, y_train)

# ElasticNet（L1 + L2）
elastic = ElasticNet(alpha=1.0, l1_ratio=0.5)  # l1_ratio=0.5は半々
elastic.fit(X_train, y_train)

# 各モデルの重みを確認
print("Ridge係数:", ridge.coef_)
print("Lasso係数:", lasso.coef_)  # いくつかは0になる
print("ElasticNet係数:", elastic.coef_)</code></pre>
                        <h6>観察ポイント</h6>
                        <ul>
                            <li>Lassoは一部の係数が完全に0になることを確認</li>
                            <li>Ridgeはすべての係数が小さな値を保持</li>
                            <li>ElasticNetは中間的な振る舞い</li>
                        </ul>
                    </div>

                    <h3 class="section-title">4.5 回帰モデルの評価指標</h3>
                    <p>
                        回帰モデルの性能を評価するには、予測値と実際の値の差を定量化する指標を使います。
                        それぞれの指標には特徴があり、用途に応じて使い分けます。
                    </p>

                    <h4>主要な評価指標</h4>

                    <h5>1. MAE（平均絶対誤差）</h5>
                    <p>
                        <strong>Mean Absolute Error</strong>: 予測値と実測値の差の絶対値の平均<br>
                        <strong>特徴</strong>:
                        <ul>
                            <li>外れ値の影響を受けにくい</li>
                            <li>元のデータと同じ単位で解釈しやすい</li>
                            <li>平均的な誤差の大きさを示す</li>
                        </ul>
                    </p>

                    <h5>2. MSE（平均二乗誤差）</h5>
                    <p>
                        <strong>Mean Squared Error</strong>: 予測値と実測値の差の二乗の平均<br>
                        <strong>特徴</strong>:
                        <ul>
                            <li>大きな誤差に対してペナルティが大きい</li>
                            <li>微分可能で最適化しやすい</li>
                            <li>単位が元データの二乗になる</li>
                        </ul>
                    </p>

                    <h5>3. RMSE（平均二乗誤差平方根）</h5>
                    <p>
                        <strong>Root Mean Squared Error</strong>: MSEの平方根<br>
                        <strong>特徴</strong>:
                        <ul>
                            <li>MSEより解釈しやすい（元データと同じ単位）</li>
                            <li>大きな誤差を重視</li>
                            <li>最も一般的に使われる指標</li>
                        </ul>
                    </p>

                    <h5>4. R²（決定係数）</h5>
                    <p>
                        <strong>R-squared（Coefficient of Determination）</strong>: モデルがデータの変動をどれだけ説明できるか<br>
                        <strong>範囲</strong>: -∞ ～ 1.0（1.0が最良）<br>
                        <strong>特徴</strong>:
                        <ul>
                            <li>0に近いとモデルの説明力が低い</li>
                            <li>1に近いとモデルがデータをよく説明</li>
                            <li>負の値は、単純な平均よりも悪い予測</li>
                        </ul>
                    </p>

                    <div class="mermaid">
                        flowchart LR
                            A[回帰評価指標] --> B["MAE<br/>（平均絶対誤差）"]
                            A --> C["MSE<br/>（平均二乗誤差）"]
                            A --> D["RMSE<br/>（二乗誤差平方根）"]
                            A --> E["R²<br/>（決定係数）"]
                            B --> F["外れ値に<br/>強い"]
                            C --> G["最適化に<br/>適する"]
                            D --> H["解釈<br/>しやすい"]
                            E --> I["説明力を<br/>評価"]
                            style A fill:#00897B,color:#fff
                    </div>

                    <div class="exercise-container">
                        <h5>実習 4-4: 評価指標の計算</h5>
                        <p>構築したモデルをさまざまな評価指標で評価します。</p>
                        <h6>実装例</h6>
                        <pre class="code-block"><code class="language-python">from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 予測
y_pred = model.predict(X_test)

# 各種評価指標の計算
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f}")    # 平均的な誤差
print(f"MSE: {mse:.2f}")    # 二乗誤差
print(f"RMSE: {rmse:.2f}")  # 標準的な誤差
print(f"R²: {r2:.3f}")       # 決定係数（0～1）

# R²の解釈
if r2 > 0.8:
    print("モデルはデータを非常によく説明しています")
elif r2 > 0.5:
    print("モデルはデータをある程度説明しています")
else:
    print("モデルの説明力は低いです")</code></pre>
                        <h6>評価の考え方</h6>
                        <p>
                            MAE/RMSEは具体的な誤差の大きさを示し、R²はモデル全体の説明力を示します。
                            複数の指標を組み合わせて総合的に評価することが重要です。
                        </p>
                    </div>

                    <h3 class="section-title">4.6 回帰モデルの使い分け</h3>
                    <p>
                        問題の特性に応じて、適切な回帰モデルを選択することが重要です。
                    </p>

                    <table class="table table-bordered">
                        <thead>
                            <tr>
                                <th>手法</th>
                                <th>適する状況</th>
                                <th>注意点</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>線形回帰</td>
                                <td>データが線形的な関係を持つ場合</td>
                                <td>非線形パターンには対応できない</td>
                            </tr>
                            <tr>
                                <td>多項式回帰</td>
                                <td>曲線的なパターンがある場合</td>
                                <td>次数が高すぎると過学習のリスク</td>
                            </tr>
                            <tr>
                                <td>Ridge</td>
                                <td>多重共線性がある場合</td>
                                <td>特徴量選択の効果はない</td>
                            </tr>
                            <tr>
                                <td>Lasso</td>
                                <td>特徴量が多く、選択したい場合</td>
                                <td>相関の高い特徴量から1つだけ選ぶ傾向</td>
                            </tr>
                            <tr>
                                <td>ElasticNet</td>
                                <td>RidgeとLassoの両方の利点が欲しい場合</td>
                                <td>パラメータ調整が2つ必要</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="quiz-container">
                        <h5>理解度確認クイズ</h5>
                        <ol>
                            <li>
                                <strong>回帰と分類の違い</strong><br>
                                回帰問題と分類問題の主な違いは何ですか？具体例を挙げて説明してください。
                            </li>
                            <li>
                                <strong>最小二乗法</strong><br>
                                線形回帰が最小二乗法を使う理由は何ですか？残差とはどのような意味ですか？
                            </li>
                            <li>
                                <strong>多項式回帰の次数</strong><br>
                                多項式回帰の次数を高くしすぎるとどのような問題が起こりますか？
                            </li>
                            <li>
                                <strong>正則化の効果</strong><br>
                                RidgeとLassoの違いは何ですか？それぞれどのような場合に有効ですか？
                            </li>
                            <li>
                                <strong>評価指標の選択</strong><br>
                                MAEとRMSEの違いは何ですか？どちらを選ぶべき状況について説明してください。
                            </li>
                            <li>
                                <strong>R²の解釈</strong><br>
                                R²（決定係数）が0.7の場合、どのように解釈すればよいですか？
                            </li>
                        </ol>
                    </div>

                    <h3 class="section-title">4.7 まとめ</h3>
                    <div class="highlight">
                        <h5>本章で学んだこと</h5>
                        <ul>
                            <li>回帰は連続値を予測する教師あり学習</li>
                            <li>線形回帰は最小二乗法で最適な直線を求める</li>
                            <li>多項式回帰は曲線的なパターンを捉えられる</li>
                            <li>正則化（Ridge、Lasso、ElasticNet）で過学習を防ぐ</li>
                            <li>MAE、RMSE、R²などの評価指標でモデルを評価</li>
                            <li>問題の特性に応じて適切なモデルを選択する</li>
                        </ul>
                    </div>

                    <div class="d-flex justify-content-between mt-4">
                        <a href="machine-learning-learning-material-03.html" class="btn btn-secondary">← 前の章</a>
                        <a href="machine-learning-learning-material-05.html" class="btn btn-primary">次の章 →</a>
                    </div>
                </div>
            </main>
        </div>
    </div>

    <footer class="bg-dark text-white mt-5">
        <div class="container-fluid py-3">
            <div class="row">
                <div class="col-12 text-center">
                    <p class="mb-0">© 2025 F-Circle. All rights reserved.<br>
本資料はAIツールを活用し、人間による編集・監修のもと作成されています。無断転載・再配布を禁じます。</p>
                </div>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default'
        });
    </script>
</body>
</html>
