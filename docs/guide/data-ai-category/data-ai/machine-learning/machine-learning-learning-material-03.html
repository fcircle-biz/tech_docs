<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>機械学習学習教材 第3章 - データの前処理</title>

    <!-- Bootstrap 5 CDN -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Google Fonts - Noto Sans JP -->
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700&display=swap" rel="stylesheet">

    <!-- Highlight.js CDN -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

    <!-- Mermaid.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>

    <style>
        body {
            font-family: 'Noto Sans JP', sans-serif;
            padding-top: 56px;
        }

        .navbar {
            background-color: #00897B;
        }

        .sidebar {
            position: sticky;
            top: 70px;
            height: calc(100vh - 70px);
            overflow-y: auto;
            background-color: #f8f9fa;
            padding: 1rem;
        }

        .chapter-title {
            color: #00897B;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            border-bottom: 3px solid #00897B;
            padding-bottom: 0.5rem;
        }

        .section-title {
            color: #26a69a;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            padding-left: 0.5rem;
            border-left: 4px solid #26a69a;
        }

        .quiz-container {
            background-color: #e0f2f1;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-left: 4px solid #00897B;
        }

        .exercise-container {
            background-color: #f3e5f5;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-left: 4px solid #9c27b0;
        }

        .highlight {
            background-color: #fff9c4;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            border-left: 4px solid #fbc02d;
        }

        .warning {
            background-color: #ffebee;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            border-left: 4px solid #f44336;
        }

        .code-block {
            background-color: #1e1e1e;
            color: white;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
        }

        .nav-link.active {
            background-color: #00897B !important;
            color: white !important;
            border-radius: 5px;
        }

        .nav-link {
            color: #333;
            transition: all 0.3s;
        }

        .nav-link:hover {
            background-color: #e0f2f1;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <!-- ナビゲーションバー -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="README.html">
                <strong>機械学習学習教材</strong>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
        </div>
    </nav>

    <div class="container-fluid">
        <div class="row">
            <!-- サイドバー -->
            <nav id="sidebarMenu" class="col-md-3 col-lg-2 d-md-block sidebar collapse">
                <div class="position-sticky pt-3">
                    <h6 class="sidebar-heading d-flex justify-content-between align-items-center px-3 mt-4 mb-1 text-muted">
                        <span>学習章</span>
                    </h6>
                    <ul class="nav flex-column">
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-01.html">
                                第1章: 機械学習の概要と環境構築
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-02.html">
                                第2章: 機械学習の基礎概念
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link active" href="machine-learning-learning-material-03.html">
                                第3章: データの前処理
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-04.html">
                                第4章: 教師あり学習：回帰
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-05.html">
                                第5章: 教師あり学習：分類
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-06.html">
                                第6章: モデルの評価と検証
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-07.html">
                                第7章: 特徴量エンジニアリング
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-08.html">
                                第8章: アンサンブル学習
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-09.html">
                                第9章: 教師なし学習
                            </a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="machine-learning-learning-material-10.html">
                                第10章: 実践プロジェクト開発
                            </a>
                        </li>
                    </ul>
                </div>
            </nav>

            <!-- メインコンテンツ -->
            <main class="col-md-9 ms-sm-auto col-lg-10 px-md-4">
                <div class="d-flex justify-content-between flex-wrap flex-md-nowrap align-items-center pt-3 pb-2 mb-3 border-bottom">
                    <h1 class="h2">第3章: データの前処理</h1>
                </div>

                <div id="chapter3">
                    <h2 class="chapter-title">データを機械学習に適した形に整える</h2>

                    <div class="highlight">
                        <h5>この章で学ぶこと</h5>
                        <ul>
                            <li>データの読み込みと基本的な確認方法</li>
                            <li>欠損値の種類とその対処法（削除、補完）</li>
                            <li>外れ値の検出と適切な処理方法</li>
                            <li>データの正規化とスケーリングの必要性</li>
                            <li>カテゴリカル変数のエンコーディング手法</li>
                        </ul>
                    </div>

                    <p>
                        <strong>データの前処理</strong>は、機械学習プロジェクトの成否を左右する極めて重要なステップです。
                        「データサイエンティストの時間の80%は前処理に費やされる」とも言われるほど、データを適切に準備することは不可欠です。
                    </p>

                    <h3 class="section-title">3.1 データの読み込みと確認</h3>

                    <p>
                        機械学習を始める前に、まずデータの全体像を把握することが重要です。
                        データの形状、型、分布を理解することで、適切な前処理方法を選択できます。
                    </p>

                    <div class="exercise-container">
                        <h5>実習 3-1: データの読み込みと基本確認</h5>
                        <p>
                            pandasを使って、サンプルデータを読み込み、データの基本情報を確認する方法を学びます。
                        </p>

                        <h6>実習コード</h6>
                        <pre class="code-block"><code class="language-python">import pandas as pd
import numpy as np

# サンプルデータの作成（実際のプロジェクトではCSVファイルから読み込む）
data = {
    '顧客ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    '年齢': [25, 30, np.nan, 45, 22, 35, 28, 50, 33, 27],
    '収入': [300, 450, 500, np.nan, 280, 520, 350, 600, 480, 310],
    '購入回数': [5, 8, 3, 12, 2, 9, 6, 15, 7, 4],
    '性別': ['男性', '女性', '男性', '女性', '男性', np.nan, '女性', '男性', '女性', '男性'],
    '会員区分': ['ゴールド', 'シルバー', 'ブロンズ', 'ゴールド', 'ブロンズ',
               'シルバー', 'ゴールド', 'プラチナ', 'シルバー', 'ブロンズ']
}

df = pd.DataFrame(data)

print("=== データの先頭5行 ===")
print(df.head())

print("\n=== データの基本情報 ===")
print(df.info())

print("\n=== 基本統計量 ===")
print(df.describe())

print("\n=== 欠損値の確認 ===")
print(df.isnull().sum())</code></pre>

                        <h6>学習ポイント</h6>
                        <ul>
                            <li><strong>head()</strong>: 先頭数行を表示し、データの雰囲気を掴む</li>
                            <li><strong>info()</strong>: 各列のデータ型、非欠損値の数、メモリ使用量を確認</li>
                            <li><strong>describe()</strong>: 数値列の平均、標準偏差、最小値、最大値などの統計量を表示</li>
                            <li><strong>isnull().sum()</strong>: 各列の欠損値の数をカウント</li>
                        </ul>
                    </div>

                    <h3 class="section-title">3.2 欠損値の処理</h3>

                    <p>
                        <strong>欠損値（Missing Value）</strong>とは、データが記録されていない、または取得できなかった箇所のことです。
                        pandasでは<code>NaN</code>（Not a Number）として表現されます。
                        欠損値を適切に処理しないと、多くの機械学習アルゴリズムはエラーを起こすため、必ず対処が必要です。
                    </p>

                    <h4>欠損値が発生する主な原因</h4>
                    <ul>
                        <li><strong>データ入力ミス</strong>: 入力時のヒューマンエラー</li>
                        <li><strong>センサー故障</strong>: IoTデバイスやセンサーの一時的な不具合</li>
                        <li><strong>回答拒否</strong>: アンケート調査での未回答</li>
                        <li><strong>データ結合時の不一致</strong>: 複数のデータソースを結合した際の欠損</li>
                    </ul>

                    <h4>欠損値の処理方法</h4>

                    <div class="mermaid">
                        flowchart TD
                            A["欠損値を発見"] --> B{"欠損の割合は?"}
                            B -->|"少量<br/>（5%未満）"| C["行削除または<br/>補完"]
                            B -->|"中程度<br/>（5-20%）"| D["補完を優先"]
                            B -->|"大量<br/>（20%以上）"| E["列削除を検討"]

                            C --> F["削除: dropna()"]
                            D --> G["補完方法を選択"]
                            G --> G1["平均値/中央値<br/>補完"]
                            G --> G2["最頻値補完"]
                            G --> G3["前後の値で補完<br/>（時系列）"]
                            G --> G4["予測モデルで補完"]
                    </div>

                    <h4>1. 欠損値の削除</h4>

                    <p>
                        欠損値が少量の場合、その行や列を削除するのが最もシンプルな方法です。
                        ただし、データ量が減少するため、慎重に判断する必要があります。
                    </p>

                    <pre class="code-block"><code class="language-python"># 欠損値を含む行を削除
df_dropped_rows = df.dropna()

# 特定の列に欠損値がある行だけ削除
df_dropped_specific = df.dropna(subset=['年齢'])

# 欠損値を含む列を削除（threshold: 最低限必要な非欠損値の数）
df_dropped_cols = df.dropna(axis=1, thresh=8)

print(f"元のデータ: {df.shape}")
print(f"行削除後: {df_dropped_rows.shape}")
print(f"列削除後: {df_dropped_cols.shape}")</code></pre>

                    <h4>2. 欠損値の補完（Imputation）</h4>

                    <p>
                        欠損値を適切な値で埋める方法です。補完する値の選び方は、データの性質に依存します。
                    </p>

                    <div class="exercise-container">
                        <h5>実習 3-2: 欠損値の補完</h5>

                        <h6>実習コード</h6>
                        <pre class="code-block"><code class="language-python">from sklearn.impute import SimpleImputer

# 元のデータをコピー
df_imputed = df.copy()

# 方法1: 平均値で補完（数値データ）
mean_age = df['年齢'].mean()
df_imputed['年齢'].fillna(mean_age, inplace=True)

# 方法2: 中央値で補完（数値データ）
median_income = df['収入'].median()
df_imputed['収入'].fillna(median_income, inplace=True)

# 方法3: 最頻値で補完（カテゴリデータ）
mode_gender = df['性別'].mode()[0]
df_imputed['性別'].fillna(mode_gender, inplace=True)

print("=== 補完後のデータ ===")
print(df_imputed)

print("\n=== 欠損値の確認 ===")
print(df_imputed.isnull().sum())

# scikit-learnのSimpleImputerを使う方法
imputer = SimpleImputer(strategy='mean')
df[['年齢', '収入']] = imputer.fit_transform(df[['年齢', '収入']])
print("\n=== SimpleImputer使用後 ===")
print(df[['年齢', '収入']])</code></pre>

                        <h6>補完方法の選び方</h6>
                        <ul>
                            <li><strong>平均値</strong>: データが正規分布に近い場合</li>
                            <li><strong>中央値</strong>: 外れ値の影響を受けにくい（推奨）</li>
                            <li><strong>最頻値</strong>: カテゴリデータに適用</li>
                            <li><strong>固定値（0など）</strong>: 欠損に特別な意味がある場合</li>
                        </ul>
                    </div>

                    <h3 class="section-title">3.3 外れ値の検出と処理</h3>

                    <p>
                        <strong>外れ値（Outlier）</strong>とは、他のデータから極端に離れた値のことです。
                        外れ値はモデルの学習に悪影響を与える可能性があるため、適切に処理する必要があります。
                    </p>

                    <h4>外れ値の検出方法</h4>

                    <div class="highlight">
                        <h6>1. IQR（四分位範囲）を使った検出</h6>
                        <p>
                            統計的に最も一般的な方法です。データを4等分し、第1四分位数（Q1）と第3四分位数（Q3）の範囲外のデータを外れ値とします。
                        </p>
                        <ul>
                            <li><strong>IQR = Q3 - Q1</strong></li>
                            <li><strong>外れ値の基準</strong>: Q1 - 1.5×IQR より小さい、または Q3 + 1.5×IQR より大きい</li>
                        </ul>
                    </div>

                    <div class="exercise-container">
                        <h5>実習 3-3: 外れ値の検出と可視化</h5>

                        <h6>実習コード</h6>
                        <pre class="code-block"><code class="language-python">import matplotlib.pyplot as plt

# サンプルデータ（外れ値を含む）
np.random.seed(42)
data_normal = np.random.normal(50, 10, 95)
data_outliers = np.array([120, 130, -20, 140, 125])  # 外れ値
data_with_outliers = np.concatenate([data_normal, data_outliers])

# IQRによる外れ値検出
Q1 = np.percentile(data_with_outliers, 25)
Q3 = np.percentile(data_with_outliers, 75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

print(f"第1四分位数 (Q1): {Q1:.2f}")
print(f"第3四分位数 (Q3): {Q3:.2f}")
print(f"IQR: {IQR:.2f}")
print(f"外れ値の範囲: {lower_bound:.2f} 〜 {upper_bound:.2f}")

# 外れ値の抽出
outliers = data_with_outliers[(data_with_outliers < lower_bound) |
                               (data_with_outliers > upper_bound)]
print(f"\n検出された外れ値: {outliers}")

# 箱ひげ図による可視化
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.boxplot(data_with_outliers)
plt.title('箱ひげ図（外れ値あり）')
plt.ylabel('値')

plt.subplot(1, 2, 2)
plt.hist(data_with_outliers, bins=20, edgecolor='black')
plt.axvline(lower_bound, color='r', linestyle='--', label='下限')
plt.axvline(upper_bound, color='r', linestyle='--', label='上限')
plt.title('ヒストグラム（外れ値あり）')
plt.xlabel('値')
plt.ylabel('頻度')
plt.legend()

plt.tight_layout()
plt.show()</code></pre>

                        <h6>外れ値の処理方法</h6>
                        <ul>
                            <li><strong>削除</strong>: 明らかなデータエラーの場合</li>
                            <li><strong>変換</strong>: 対数変換などで影響を軽減</li>
                            <li><strong>キャップ</strong>: 上限・下限で値を制限（Winsorization）</li>
                            <li><strong>保持</strong>: 意味のある極端な値の場合は保持</li>
                        </ul>
                    </div>

                    <h3 class="section-title">3.4 データの正規化とスケーリング</h3>

                    <p>
                        <strong>正規化（Normalization）</strong>と<strong>スケーリング（Scaling）</strong>は、
                        異なる尺度を持つ特徴量を統一する処理です。多くの機械学習アルゴリズムでは、
                        特徴量のスケールが揃っていないと正しく学習できません。
                    </p>

                    <div class="warning">
                        <h6>スケーリングが必要な理由</h6>
                        <p>
                            例えば、「年齢（20〜80）」と「年収（200万〜2000万）」を特徴量として使う場合、
                            年収の値が年齢よりも圧倒的に大きいため、モデルは年収だけを重視してしまう可能性があります。
                            これを防ぐため、すべての特徴量を同じスケール（例: 0〜1の範囲）に変換します。
                        </p>
                    </div>

                    <h4>主なスケーリング手法</h4>

                    <div class="mermaid">
                        flowchart TD
                            A["スケーリング手法"] --> B["Min-Maxスケーリング<br/>（正規化）"]
                            A --> C["標準化<br/>（Standardization）"]
                            A --> D["ロバストスケーリング"]

                            B --> B1["0〜1の範囲に変換<br/>外れ値の影響を受けやすい"]
                            C --> C1["平均0、標準偏差1に変換<br/>最も一般的"]
                            D --> D1["中央値と四分位範囲を使用<br/>外れ値に頑健"]
                    </div>

                    <h4>1. Min-Maxスケーリング（正規化）</h4>

                    <p>
                        データを0〜1の範囲に変換します。最小値が0、最大値が1になるように線形変換します。
                    </p>

                    <p><strong>式</strong>: x_scaled = (x - x_min) / (x_max - x_min)</p>

                    <h4>2. 標準化（Standardization）</h4>

                    <p>
                        データを平均0、標準偏差1に変換します。最も広く使用される手法です。
                    </p>

                    <p><strong>式</strong>: x_scaled = (x - mean) / std</p>

                    <div class="exercise-container">
                        <h5>実習 3-4: データのスケーリング</h5>

                        <h6>実習コード</h6>
                        <pre class="code-block"><code class="language-python">from sklearn.preprocessing import MinMaxScaler, StandardScaler

# サンプルデータ
data_scale = {
    '年齢': [25, 30, 35, 40, 45, 50],
    '年収(万円)': [300, 450, 600, 750, 900, 1050],
    '購入回数': [5, 8, 12, 15, 20, 25]
}

df_scale = pd.DataFrame(data_scale)

print("=== 元のデータ ===")
print(df_scale)

# Min-Maxスケーリング
scaler_minmax = MinMaxScaler()
df_minmax = pd.DataFrame(
    scaler_minmax.fit_transform(df_scale),
    columns=df_scale.columns
)

print("\n=== Min-Maxスケーリング後（0〜1の範囲）===")
print(df_minmax)

# 標準化
scaler_standard = StandardScaler()
df_standard = pd.DataFrame(
    scaler_standard.fit_transform(df_scale),
    columns=df_scale.columns
)

print("\n=== 標準化後（平均0、標準偏差1）===")
print(df_standard)

# 標準化後の確認
print("\n=== 標準化後の統計量 ===")
print(f"平均値: \n{df_standard.mean()}")
print(f"\n標準偏差: \n{df_standard.std()}")</code></pre>

                        <h6>使い分けのポイント</h6>
                        <ul>
                            <li><strong>Min-Maxスケーリング</strong>: ニューラルネットワーク、画像データ（ピクセル値を0〜1に）</li>
                            <li><strong>標準化</strong>: 線形回帰、ロジスティック回帰、SVM、k-meansなど（最も汎用的）</li>
                            <li><strong>ロバストスケーリング</strong>: 外れ値が多いデータ</li>
                        </ul>
                    </div>

                    <h3 class="section-title">3.5 カテゴリカル変数のエンコーディング</h3>

                    <p>
                        <strong>カテゴリカル変数</strong>とは、「性別」「職業」「商品カテゴリ」など、
                        カテゴリやラベルを表す変数です。機械学習アルゴリズムは数値しか扱えないため、
                        これらを数値に変換する<strong>エンコーディング</strong>が必要です。
                    </p>

                    <h4>主なエンコーディング手法</h4>

                    <h4>1. ラベルエンコーディング（Label Encoding）</h4>

                    <p>
                        各カテゴリに整数を割り当てる最もシンプルな方法です。
                        例：「低」→0、「中」→1、「高」→2
                    </p>

                    <div class="warning">
                        <h6>注意点</h6>
                        <p>
                            ラベルエンコーディングは、カテゴリ間に順序関係がない場合（名義尺度）には適していません。
                            例えば、「赤」→0、「青」→1、「緑」→2とした場合、「青は赤と緑の中間」という誤った関係性をモデルが学習してしまう可能性があります。
                            順序関係がある場合（順序尺度：「小」「中」「大」など）のみ使用してください。
                        </p>
                    </div>

                    <h4>2. One-Hotエンコーディング</h4>

                    <p>
                        各カテゴリを独立した2値（0または1）の列に変換する方法です。
                        カテゴリ間に順序関係がない場合に推奨されます。
                    </p>

                    <div class="highlight">
                        <h6>One-Hotエンコーディングの例</h6>
                        <p>元のデータ：</p>
                        <table class="table table-sm">
                            <tr><th>色</th></tr>
                            <tr><td>赤</td></tr>
                            <tr><td>青</td></tr>
                            <tr><td>緑</td></tr>
                        </table>
                        <p>変換後：</p>
                        <table class="table table-sm">
                            <tr><th>色_赤</th><th>色_青</th><th>色_緑</th></tr>
                            <tr><td>1</td><td>0</td><td>0</td></tr>
                            <tr><td>0</td><td>1</td><td>0</td></tr>
                            <tr><td>0</td><td>0</td><td>1</td></tr>
                        </table>
                    </div>

                    <div class="exercise-container">
                        <h5>実習 3-5: カテゴリカル変数のエンコーディング</h5>

                        <h6>実習コード</h6>
                        <pre class="code-block"><code class="language-python">from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# サンプルデータ
data_cat = {
    '顧客ID': [1, 2, 3, 4, 5],
    '年齢': [25, 30, 35, 40, 45],
    '性別': ['男性', '女性', '男性', '女性', '男性'],
    '会員ランク': ['ブロンズ', 'シルバー', 'ゴールド', 'シルバー', 'プラチナ']
}

df_cat = pd.DataFrame(data_cat)
print("=== 元のデータ ===")
print(df_cat)

# ラベルエンコーディング（会員ランクには順序があるため適用）
rank_mapping = {'ブロンズ': 0, 'シルバー': 1, 'ゴールド': 2, 'プラチナ': 3}
df_cat['会員ランク_encoded'] = df_cat['会員ランク'].map(rank_mapping)

print("\n=== ラベルエンコーディング後 ===")
print(df_cat[['会員ランク', '会員ランク_encoded']])

# One-Hotエンコーディング（性別には順序がないため適用）
df_encoded = pd.get_dummies(df_cat, columns=['性別'], prefix='性別')

print("\n=== One-Hotエンコーディング後 ===")
print(df_encoded)</code></pre>

                        <h6>エンコーディング手法の選び方</h6>
                        <ul>
                            <li><strong>ラベルエンコーディング</strong>: 順序関係があるカテゴリ（小・中・大、学歴など）</li>
                            <li><strong>One-Hotエンコーディング</strong>: 順序関係がないカテゴリ（色、職業、地域など）</li>
                        </ul>
                    </div>

                    <div class="quiz-container">
                        <h5>理解度確認クイズ</h5>
                        <ol>
                            <li>
                                <strong>欠損値を補完する際、平均値よりも中央値を使った方が良いのはどのような場合ですか？</strong>
                                <details>
                                    <summary>解答を表示</summary>
                                    <p>
                                        外れ値が存在する場合です。平均値は外れ値の影響を大きく受けますが、
                                        中央値は外れ値の影響を受けにくく、より頑健な補完ができます。
                                        例えば、年収データに極端に高い値がある場合、中央値を使う方が適切です。
                                    </p>
                                </details>
                            </li>
                            <li>
                                <strong>機械学習でスケーリングが必要な理由を説明してください。</strong>
                                <details>
                                    <summary>解答を表示</summary>
                                    <p>
                                        特徴量間でスケール（値の範囲）が大きく異なると、値が大きい特徴量だけが重視され、
                                        モデルが正しく学習できない可能性があります。スケーリングにより、
                                        すべての特徴量を同じスケールに揃えることで、公平に評価できるようになります。
                                    </p>
                                </details>
                            </li>
                            <li>
                                <strong>Min-Maxスケーリングと標準化の違いを説明してください。</strong>
                                <details>
                                    <summary>解答を表示</summary>
                                    <p>
                                        <strong>Min-Maxスケーリング</strong>: データを0〜1の範囲に変換。最小値が0、最大値が1になる。<br>
                                        <strong>標準化</strong>: データを平均0、標準偏差1に変換。値の範囲は固定されない。<br>
                                        標準化の方が外れ値に対して頑健で、多くのアルゴリズムで推奨されます。
                                    </p>
                                </details>
                            </li>
                            <li>
                                <strong>カテゴリカル変数に対して、ラベルエンコーディングとOne-Hotエンコーディングを使い分ける基準は何ですか？</strong>
                                <details>
                                    <summary>解答を表示</summary>
                                    <p>
                                        <strong>ラベルエンコーディング</strong>: カテゴリ間に順序関係がある場合（例：小・中・大、学歴）<br>
                                        <strong>One-Hotエンコーディング</strong>: カテゴリ間に順序関係がない場合（例：色、職業、地域）<br>
                                        順序関係がないカテゴリにラベルエンコーディングを使うと、誤った順序関係をモデルが学習してしまいます。
                                    </p>
                                </details>
                            </li>
                            <li>
                                <strong>外れ値を検出するIQR法の仕組みを説明してください。</strong>
                                <details>
                                    <summary>解答を表示</summary>
                                    <p>
                                        IQR（四分位範囲）= Q3（第3四分位数）- Q1（第1四分位数）を計算し、
                                        Q1 - 1.5×IQR より小さい、または Q3 + 1.5×IQR より大きい値を外れ値と判定します。
                                        この範囲外のデータは、統計的に異常な値とみなされます。
                                    </p>
                                </details>
                            </li>
                        </ol>
                    </div>

                    <h3 class="section-title">3.6 まとめ</h3>

                    <p>
                        この章では、データの前処理の重要性と主要な手法を学びました。
                        前処理は地味な作業ですが、モデルの性能に直結する極めて重要なステップです。
                    </p>

                    <div class="highlight">
                        <h6>重要ポイント</h6>
                        <ul>
                            <li><strong>データ確認</strong>: head(), info(), describe()で全体像を把握</li>
                            <li><strong>欠損値処理</strong>: 削除または補完（平均値、中央値、最頻値）</li>
                            <li><strong>外れ値処理</strong>: IQR法で検出し、削除・変換・キャップを適用</li>
                            <li><strong>スケーリング</strong>: Min-Maxスケーリングまたは標準化で特徴量の尺度を統一</li>
                            <li><strong>エンコーディング</strong>: カテゴリカル変数を数値に変換（ラベルまたはOne-Hot）</li>
                        </ul>
                    </div>

                    <p>
                        次の第4章では、教師あり学習の代表的な手法である「回帰」について学びます。
                        線形回帰、多項式回帰、正則化などの理論と実装を習得します。
                    </p>

                    <div class="d-flex justify-content-between mt-4">
                        <a href="machine-learning-learning-material-02.html" class="btn btn-secondary">← 前の章</a>
                        <a href="machine-learning-learning-material-04.html" class="btn btn-primary">次の章 →</a>
                    </div>
                </div>
            </main>
        </div>
    </div>

    <!-- フッター -->
    <footer class="bg-dark text-white mt-5">
        <div class="container-fluid py-3">
            <div class="row">
                <div class="col-12 text-center">
                    <p class="mb-0">© 2025 F-Circle. All rights reserved.<br>
本資料はAIツールを活用し、人間による編集・監修のもと作成されています。無断転載・再配布を禁じます。</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- Bootstrap JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Highlight.js 初期化 -->
    <script>hljs.highlightAll();</script>

    <!-- Mermaid.js 初期化 -->
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default'
        });
    </script>
</body>
</html>